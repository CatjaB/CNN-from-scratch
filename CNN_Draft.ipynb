{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7-b6RJA2z6U"
      },
      "outputs": [],
      "source": [
        "#import torch package. \n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlHfWYKHTFyq"
      },
      "outputs": [],
      "source": [
        "# Check available devices\n",
        "# Device configuration\n",
        "\n",
        "torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ee0NWkeTF05"
      },
      "outputs": [],
      "source": [
        "# What? Download MNIST dataset in local system\n",
        "# How: download MNIST dataset through torchvision for train and test data separately and transform both into numpy.ndarray\n",
        "\n",
        "from torchvision import datasets\n",
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data', #root (string) – Root directory of dataset where mnist file exists\n",
        "    train = True,   #train (bool, optional) – If True, creates dataset from train imageset, otherwise from other imageset                      \n",
        "    transform = ToTensor(), #ToTensor() = Convert a PIL Image or numpy.ndarray to tensor.\n",
        "    download = True,    #download (bool, optional) – If True, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.        \n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data', \n",
        "    train = False, \n",
        "    transform = ToTensor()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4l0B_GRDfwp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TikTPJCeTF3A"
      },
      "outputs": [],
      "source": [
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "estVJel6TF5I"
      },
      "outputs": [],
      "source": [
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhkYzW9LFYhc"
      },
      "outputs": [],
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6uJCiNJCwLF"
      },
      "outputs": [],
      "source": [
        "#get image and label in position 0\n",
        "img_tensor, label = train_data[0]\n",
        "#print the shape of the array of image and the label\n",
        "print(img_tensor.shape, label)\n",
        "\n",
        "#output = 1 channel, height/width 28, height/width 28, label = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xtd1HmYEF7jq"
      },
      "outputs": [],
      "source": [
        "img_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWvhW4hHGTy9"
      },
      "source": [
        "According to the three cells before:\n",
        "\n",
        "\n",
        "* train_data contains 60000 elements\n",
        "* test_data contains 10000 elements\n",
        "* 1 image has 1 channel (pixel number shows the value between black and white), and the height and width 28 x 28 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AniOXVedTF_e"
      },
      "outputs": [],
      "source": [
        "#Plot one train_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data.data[0], cmap='gray', vmin=0, vmax=255)\n",
        "#print title as number from train_data.targets\n",
        "plt.title('%i' % train_data.targets[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj255MYJTigx"
      },
      "source": [
        "## Prepare data for training with DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrW7nturTGFs"
      },
      "outputs": [],
      "source": [
        "# DataLoader is an iterable that abstracts this complexity for us in an easy API.\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "#data is put into dict with two entries: train & test\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data, #dataset (Dataset) – dataset from which to load the data.\n",
        "                                          batch_size=100, #batch_size (int, optional) – how many samples per batch to load (default: 1). 100 individual fetched data samples are put into 1 batch\n",
        "                                          shuffle=True, #shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False) If shuffle is set to True, then all the samples are shuffled and loaded in batches. Otherwise they are sent one-by-one without any shuffling.\n",
        "                                          num_workers=1), #num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "}\n",
        "loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDetcz_qbquR"
      },
      "outputs": [],
      "source": [
        "loaders['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoTgmSfHc1ML"
      },
      "outputs": [],
      "source": [
        "data = next(iter(loaders['train']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWHaTlm20xp1"
      },
      "source": [
        "# Pre-Class Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuj-PFpEiLkg"
      },
      "outputs": [],
      "source": [
        "#@title Padding Function\n",
        "def add_padding(img, padding):\n",
        "  #per channel\n",
        "  output = torch.empty((img.size()[0],img.size()[2]+2*padding, img.size()[2]+2*padding))\n",
        "  for c in range(img.size(dim=0)):\n",
        "    #per row\n",
        "    for row in range(img.size(dim=1)):\n",
        "      #per column value\n",
        "      for value in range(img.size(dim=2)):\n",
        "        output[c][row+padding][value+padding] = img[c][row][value]\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2rq-R_sl1S1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eADWubvVigMq"
      },
      "outputs": [],
      "source": [
        "input_img = torch.tensor([[[2,0,0,1,0],\n",
        "                          [0,2,0,0,2],\n",
        "                          [0,2,0,2,2],\n",
        "                          [0,2,0,2,1],\n",
        "                          [0,2,2,2,1]],\n",
        "\n",
        "                          [[2,0,0,1,0],\n",
        "                          [0,1,0,0,0],\n",
        "                          [2,1,1,2,1],\n",
        "                          [0,0,1,1,1],\n",
        "                          [1,2,0,1,1]],\n",
        "\n",
        "                          [[2,0,0,1,0],\n",
        "                          [1,1,2,1,2],\n",
        "                          [2,2,1,2,2],\n",
        "                          [0,0,0,0,0],\n",
        "                          [2,1,2,2,0]]], dtype=torch.long)\n",
        "\n",
        "padded = add_padding(input_img, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMF6LVb-nmBc"
      },
      "outputs": [],
      "source": [
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V42Y1clJnmDr"
      },
      "outputs": [],
      "source": [
        "#@title sum_img_filter Function\n",
        "def sum_img_filter(img_slice, filter, bias):\n",
        "  value_sum = 0\n",
        "  for c in range(len(filter)):\n",
        "    for row in range(len(img_slice[c])):\n",
        "      for v in range(len(img_slice[c][row])):\n",
        "        value = img_slice[c][row][v] * filter[c][row][v]\n",
        "        value_sum += value\n",
        "  value_sum = value_sum + bias\n",
        "  return value_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFqznH10KZG_"
      },
      "outputs": [],
      "source": [
        "tensor1 = torch.randn(3,3)\n",
        "tensor2 = torch.randn(3,3)\n",
        "\n",
        "print(tensor1)\n",
        "print(tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGzOqVoEKR6F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "b = torch.matmul(tensor1, tensor2)\n",
        "\n",
        "c = np.tensordot(tensor1,tensor2, 1)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LrH0-ugentq"
      },
      "outputs": [],
      "source": [
        "a_ten = torch.tensor([[[2,0,0],\n",
        "                          [0,2,0],\n",
        "                          [0,2,0]],\n",
        "\n",
        "                          [[2,0,0],\n",
        "                          [0,1,0],\n",
        "                          [2,1,1]],\n",
        "\n",
        "                          [[2,0,0],\n",
        "                          [1,1,2],\n",
        "                          [2,2,1]]], dtype=torch.long)\n",
        "filter_ten = torch.tensor(             [[[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]],\n",
        "\n",
        "                          [[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]],\n",
        "\n",
        "                          [[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2IzOWD4fKnR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "b = torch.matmul(a_ten, filter_ten)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w65cTUPjfqPw"
      },
      "outputs": [],
      "source": [
        "np_a = a_ten.numpy()\n",
        "np_filter = filter_ten.numpy()\n",
        "\n",
        "\n",
        "e = np.matmul(np_a, np_filter)\n",
        "e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Kxfqme-TBqO"
      },
      "outputs": [],
      "source": [
        "print(a_ten[0][1][:])\n",
        "print(np_a[0][1][:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67tJlrVPTByb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xezBo788enyG"
      },
      "outputs": [],
      "source": [
        "a = np.array(             [[[2,0,0],\n",
        "                          [0,2,0],\n",
        "                          [0,2,0]],\n",
        "\n",
        "                          [[2,0,0],\n",
        "                          [0,1,0],\n",
        "                          [2,1,1]],\n",
        "\n",
        "                          [[2,0,0],\n",
        "                          [1,1,2],\n",
        "                          [2,2,1]]])\n",
        "\n",
        "\n",
        "filter = np.array(             [[[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]],\n",
        "\n",
        "                          [[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]],\n",
        "\n",
        "                          [[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRznkNiHen2R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "d = np.matmul(a, filter)\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PXVASmYen5i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh1T3zlkSU3i"
      },
      "outputs": [],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX6pe-U9_5ze"
      },
      "outputs": [],
      "source": [
        "#@title img_slice_x_filters Function\n",
        "def img_slice_x_filters(img, size, stride, row, filter, bias):\n",
        "    slices = []\n",
        "    v = 0\n",
        "\n",
        "    while (v + size) <= img.size(dim=2):\n",
        "        #one slice\n",
        "        one_slice = img[:, row : row + size, v : v + size]\n",
        "        v = v + stride\n",
        "        slices.append(one_slice)\n",
        "\n",
        "    #per tensor:\n",
        "    final_values = []\n",
        "\n",
        "    for a_slice in range(len(slices)):\n",
        "      calc = matrix_sum_img_filter(slices[a_slice], filter, bias.item())\n",
        "      final_values.append(calc)\n",
        "      \n",
        "    return final_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jetZ4lT8hCXG"
      },
      "outputs": [],
      "source": [
        "\n",
        "slices_img = torch.tensor([[[2,0,0,1,0],\n",
        "                          [0,2,0,0,2],\n",
        "                          [0,2,0,2,2],\n",
        "                          [0,2,0,2,1],\n",
        "                          [0,2,2,2,1]]], dtype=torch.long)\n",
        "\n",
        "\n",
        "test_filters = torch.tensor([[[[-1,1,1],\n",
        "                              [-1,-1,0],\n",
        "                              [1,-1,1]]],\n",
        "\n",
        "                             [[[-1,1,1],\n",
        "                              [-1,-1,0],\n",
        "                              [1,-1,1]]],\n",
        "\n",
        "                              [[[-1,1,1],\n",
        "                              [-1,-1,0],\n",
        "                              [1,-1,1]]]])\n",
        "\n",
        "\n",
        "output = img_slice_x_filters(slices_img, 3, 2, 0, test_filters[0], torch.tensor([1]))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDRfd-ci_54G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysycKAPLeuL3"
      },
      "outputs": [],
      "source": [
        "#@title max_slice Function\n",
        "def max_slice(input, size, stride, row):\n",
        "    max_values = []\n",
        "    v = 0\n",
        "    while (v + size) <= len(input):\n",
        "      one_slice = input[row : row + size, v : v + size]\n",
        "      v = v + stride\n",
        "      max_val = torch.max(one_slice)\n",
        "      max_values.append(max_val.item())\n",
        "\n",
        "    return max_values\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhCl9qsveuJ6"
      },
      "outputs": [],
      "source": [
        "slices_img = torch.tensor([[[2,0,0,1,0],\n",
        "                          [0,2,0,0,2],\n",
        "                          [0,2,0,2,2],\n",
        "                          [0,2,0,2,1],\n",
        "                          [0,3,2,2,1]],\n",
        "\n",
        "                          [[2,0,0,1,0],\n",
        "                          [0,1,0,0,0],\n",
        "                          [2,1,1,2,1],\n",
        "                          [0,0,1,1,1],\n",
        "                          [1,2,0,1,1]]], dtype=torch.long)\n",
        "\n",
        "\n",
        "max_slice(slices_img[0], 3, 2, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNBAf6rf_56I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1s8nBne-BOC"
      },
      "outputs": [],
      "source": [
        "\n",
        "filters = torch.rand((2, 3, 3))\n",
        "\n",
        "filters.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8baCP1gj-BRr"
      },
      "outputs": [],
      "source": [
        "print(\"filters \", filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu31NXb1BfxD"
      },
      "outputs": [],
      "source": [
        "filters[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpeIwxSsBfts"
      },
      "outputs": [],
      "source": [
        "\n",
        "bias = torch.rand(3)\n",
        "\n",
        "bias.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDDtXoEoBfqR"
      },
      "outputs": [],
      "source": [
        "bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4j40fdI-BUv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o0PHda5CHhV"
      },
      "source": [
        "# Own Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWE2UHGFCRyB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boE4yNXhBveK"
      },
      "outputs": [],
      "source": [
        "#@title Class Conv Layer\n",
        "import torch\n",
        "import math\n",
        "from torch.nn.parameter import Parameter, UninitializedParameter\n",
        "\n",
        "\n",
        "class new_conv_layer(torch.nn.Module):\n",
        "    run_tests = False\n",
        "    def __init__(self, in_channels: int,  out_channels: int, kernel_size: int, stride: int, padding: int):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate four parameters and assign them as\n",
        "        member parameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.f_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.n_filter = out_channels\n",
        "        self.stride = stride\n",
        "        self.channels = in_channels\n",
        "\n",
        "        #creates a tensor, shape n_filter x filter, each of the size f_size and \n",
        "        #fill them with with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
        "        #in_channels = filter number, out_channels, kernel_size, kernel_size\n",
        "        self.filters = Parameter(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.bias = Parameter(torch.rand(out_channels, 1))\n",
        "\n",
        "        self.test_filters = torch.rand((out_channels, kernel_size, kernel_size, in_channels))\n",
        "        self.test_bias = torch.rand((out_channels, 1))\n",
        "\n",
        "    def set_filter_bias(self, test_filters, test_bias):\n",
        "        self.test_filters = test_filters\n",
        "        self.test_bias = test_bias\n",
        "\n",
        "    def get_filters(self):\n",
        "        print(self.filters)\n",
        "\n",
        "    def get_bias(self):\n",
        "        print(self.bias)\n",
        "\n",
        "    def forward(self, img):\n",
        "        #add padding\n",
        "        padded_img = add_padding(img, self.padding)\n",
        "      \n",
        "        #per filter get img_slice\n",
        "        output_size = math.ceil(((img.size(dim=1) - self.f_size + 2 * self.padding)/self.stride) + 1)\n",
        "        \n",
        "        conv_output = []\n",
        "        for f in range(self.n_filter):\n",
        "          output_row= []\n",
        "          \n",
        "          if not run_tests:\n",
        "            row = 0\n",
        "            for r in range(output_size):\n",
        "              \n",
        "              slice_value = img_slice_x_filters(padded_img, self.f_size, self.stride, row, self.filters[f], self.bias[f])\n",
        "             \n",
        "              output_row.append(slice_value)\n",
        "              row += self.stride \n",
        "            conv_output.append(output_row)\n",
        "\n",
        "          else:\n",
        "            row = 0\n",
        "            for r in range(output_size):\n",
        "        \n",
        "              slice_value = img_slice_x_filters(padded_img, self.f_size, self.stride, row, self.test_filters[f], self.test_bias[f])\n",
        "              output_row.append(slice_value)\n",
        "            \n",
        "              row += self.stride \n",
        "            conv_output.append(output_row)\n",
        "          \n",
        "        return torch.tensor(conv_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRdSTFRq_hbW"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn = new_conv_layer(in_channels=1,           \n",
        "                  out_channels=2,      \n",
        "                  kernel_size=3,           \n",
        "                  stride=2,           \n",
        "                  padding=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.random.randn(3, 3, 3, 3) * np.sqrt(1. / (3)))"
      ],
      "metadata": {
        "id": "XtLSqpOipsAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuKJqK_l_RLR"
      },
      "outputs": [],
      "source": [
        "\n",
        "  #Test forward function\n",
        "  test_input = torch.tensor([[[2,0,0,2,1],\n",
        "                          [0,2,1,2,0],\n",
        "                          [1,1,0,1,1],\n",
        "                          [0,2,0,0,0],\n",
        "                          [2,1,0,2,2]],\n",
        "\n",
        "                          [[1,2,2,1,0],\n",
        "                          [2,0,1,0,2],\n",
        "                          [2,1,0,1,0],\n",
        "                          [0,2,1,2,0],\n",
        "                          [1,1,0,1,0]],\n",
        "\n",
        "                          [[0,2,2,1,2],\n",
        "                          [1,2,2,2,0],\n",
        "                          [1,1,1,2,1],\n",
        "                          [1,2,0,2,0],\n",
        "                          [1,0,2,0,1]]], dtype=torch.long)\n",
        "  \n",
        "\n",
        "  #Correct: ((in_channels = filter number, out_channels, kernel_size, kernel_size))\n",
        "\n",
        "  \n",
        "  test_filter1 = torch.tensor([[[1,-1,-1],\n",
        "                              [1,1,0],\n",
        "                              [-1,1,1]],\n",
        "\n",
        "                              [[1,0,0],\n",
        "                              [1,1,1],\n",
        "                              [1,-1,1]],\n",
        "\n",
        "                              [[0,1,0],\n",
        "                              [1,0,0],\n",
        "                              [-1,-1,1]]])\n",
        "  test_filter2 = torch.tensor([[[-1,1,1],\n",
        "                              [0,-1,0],\n",
        "                              [-1,1,-1]],\n",
        "\n",
        "                              [[0,0,0],\n",
        "                              [1,-1,0],\n",
        "                              [0,-1,1]],\n",
        "\n",
        "                              [[1,-1,0],\n",
        "                              [-1,1,0],\n",
        "                              [0,1,1]]])\n",
        "  \n",
        "  test_filters = torch.tensor([[[[1,-1,-1],\n",
        "                              [1,1,0],\n",
        "                              [-1,1,1]],\n",
        "\n",
        "                              [[1,0,0],\n",
        "                              [1,1,1],\n",
        "                              [1,-1,1]],\n",
        "\n",
        "                              [[0,1,0],\n",
        "                              [1,0,0],\n",
        "                              [-1,-1,1]]],\n",
        "                              \n",
        "                              [[[-1,1,1],\n",
        "                              [0,-1,0],\n",
        "                              [-1,1,-1]],\n",
        "\n",
        "                              [[0,0,0],\n",
        "                              [1,-1,0],\n",
        "                              [0,-1,1]],\n",
        "\n",
        "                              [[1,-1,0],\n",
        "                              [-1,1,0],\n",
        "                              [0,1,1]]]], dtype=torch.long)\n",
        "  \n",
        "\n",
        "\n",
        "  #test_filters.type(torch.LongTensor)\n",
        "  \n",
        "\n",
        "  test_bias1 = torch.tensor([[[1]]])\n",
        "  test_bias2 = torch.tensor([[[0]]])\n",
        "\n",
        "  test_bias = torch.tensor([[1],[0]])\n",
        " \n",
        "\n",
        "\n",
        "  filters = torch.rand((1, 2, 3, 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGh8A6NuBw4V"
      },
      "outputs": [],
      "source": [
        "  filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "642pb5pBCCDd"
      },
      "outputs": [],
      "source": [
        "filters[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By0xsCwL_iY1"
      },
      "outputs": [],
      "source": [
        "test_filters.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSQXR45UCCtj"
      },
      "outputs": [],
      "source": [
        "test_filters[0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCnvpJS9iG0X"
      },
      "outputs": [],
      "source": [
        "bias = torch.rand((16, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOB7IrZfiJsq"
      },
      "outputs": [],
      "source": [
        "bias[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyq45rE5DQ72"
      },
      "outputs": [],
      "source": [
        "\n",
        "  #Test forward function\n",
        "  filters = torch.rand([16, 1, 5, 5])\n",
        "  img = torch.rand([1, 28, 28])\n",
        "  \n",
        "\n",
        "  cnn = new_conv_layer(in_channels=1,           \n",
        "                  out_channels=16,      \n",
        "                  kernel_size=5,           \n",
        "                  stride=1,           \n",
        "                  padding=2)\n",
        "\n",
        " \n",
        "  output = cnn.forward(img)\n",
        "\n",
        "  print(output.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FyohsLZNNEv"
      },
      "outputs": [],
      "source": [
        "test_bias = torch.tensor([[0.4792],\n",
        "        [0.6163]])\n",
        "\n",
        "\n",
        "print(test_bias[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOxK5g1eRgi1"
      },
      "outputs": [],
      "source": [
        "test_bias = torch.tensor([[1],[0]])\n",
        "print(test_bias[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4gh6j2lNNze"
      },
      "outputs": [],
      "source": [
        "orig_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-PTZ_f4JsYU"
      },
      "outputs": [],
      "source": [
        "  cnn.filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAtJo6bfJ_6I"
      },
      "outputs": [],
      "source": [
        "  filter = [[[-1, -1, -1], \n",
        "            [1,1,1], \n",
        "            [0, 0, 0]]]\n",
        "          \n",
        "  filter = torch.tensor(filter)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RF0YacpDRCY"
      },
      "outputs": [],
      "source": [
        "  # test forward function\n",
        "  import numpy as np\n",
        "\n",
        "  torch_img = torch.tensor([[0, 0, 0, 0, 0, 0], \n",
        "                [1, 2, 3, 4, 5, 6], \n",
        "                [0, 0, 0, 0, 0, 0],\n",
        "                [1, 1, 1, 1, 1, 1],\n",
        "                [0, 0, 0, 0, 0, 0],\n",
        "                [0, 0, 0, 0, 0, 0]])\n",
        "\n",
        "  torch_img = torch_img.float()\n",
        "  len(torch_img[0])       \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJJJT22oHjOw"
      },
      "outputs": [],
      "source": [
        "filter_size = 3\n",
        "stride = 1\n",
        "k_s = 0\n",
        "j_s = 4\n",
        "img_slice = torch_img[j_s:filter_size+j_s, stride*k_s :filter_size + k_s]\n",
        "img_slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYw7-1K-HxIt"
      },
      "outputs": [],
      "source": [
        "conv_layer = cnn.forward(torch_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4TVrI_gLnO9"
      },
      "outputs": [],
      "source": [
        "np_img = np.array([[0., 0., 0.],\n",
        "          [1., 2., 3.],\n",
        "          [0., 0., 0.]])\n",
        "np_filters =  np.array([[0.6399, 0.3915, 0.6495],\n",
        "          [0.6554, 0.1948, 0.8741],\n",
        "          [0.1062, 0.6698, 0.5635]])\n",
        "value=  3.6674\n",
        "value_correc = np.dot(np_img, np_filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6j46opNMAzY"
      },
      "outputs": [],
      "source": [
        "value_correc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_R3qrYuLz9c"
      },
      "outputs": [],
      "source": [
        "final_value = np.sum(value_correc)\n",
        "final_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d9c3o8lDRFZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "conv_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7JSAjMuDRHp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzD_bhLzCRz6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtrEJA3NAPqW"
      },
      "outputs": [],
      "source": [
        "#@title Class ReLU layer\n",
        "class new_relu_layer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, input):\n",
        "      for col in range(input.size(dim=0)):\n",
        "        for row in range(len(input[col])):        \n",
        "          for v in range(len(input[col][row])):          \n",
        "            input[col][row][v] = max(0, input[col][row][v])            \n",
        "      return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jofNFlzUULQY"
      },
      "outputs": [],
      "source": [
        "if 2 == 2: #@TODO: put run_tests in here!\n",
        "  relu_input = torch.tensor([[[ 7.,  6.,  0.],\n",
        "         [ 9.,  7.,  8.],\n",
        "         [ 4.,  8.,  8.]],\n",
        "\n",
        "        [[-4.,  0., -3.],\n",
        "         [ 2.,  3., -1.],\n",
        "         [-1.,  3.,  2.]]], dtype=torch.long)\n",
        "  cnn_relu = new_relu_layer()\n",
        "  output = cnn_relu.forward(relu_input)\n",
        "\n",
        "  print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f3uHyKXXtxt"
      },
      "outputs": [],
      "source": [
        "  relu_input = torch.tensor([[[ 7.,  6.,  0.],\n",
        "         [ 9.,  7.,  8.],\n",
        "         [ 4.,  8.,  8.]],\n",
        "\n",
        "        [[-4.,  0., -3.],\n",
        "         [ 2.,  3., -1.],\n",
        "         [-1.,  3.,  2.]],\n",
        "         \n",
        "         [[-4.,  0., -3.],\n",
        "         [ 2.,  3., -1.],\n",
        "         [-1.,  3.,  2.]]], dtype=torch.long)\n",
        "  cnn_relu = new_relu_layer()\n",
        "  output = cnn_relu.forward(relu_input)\n",
        "\n",
        "  print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGbYnoneNxaI"
      },
      "outputs": [],
      "source": [
        "\n",
        "  relu_tensor =  torch.tensor([[0.0000, 0.0000, 0.0000,  0.0000, 0.0000, 0.0000],\n",
        "          [0.0000, 0.0000, 0.0000,  0.8961, 0.3806, 0.1673],\n",
        "          [0.0000, 0.0000, 0.0000,  7.8617, 5.1243, 2.7039],\n",
        "          [0.0000, 0.0000, 0.0000,  0.0000, 0.0000, 0.0000],\n",
        "          [0.0000, 0.0000, 0.0000,  0.0000, 0.0000, 0.0000],\n",
        "          [0.0000, 0.0000, 0.0000,  0.0000, 0.0000, 0.0000]])\n",
        "\n",
        "  relu_tensor = max(0, relu_tensor[0][5])\n",
        "\n",
        "  relu_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhutM78cb3Uz"
      },
      "outputs": [],
      "source": [
        "\n",
        "  #test relu_layer\n",
        "  relu = relu_layer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjVCuFfbdJ5k"
      },
      "outputs": [],
      "source": [
        "  \n",
        "  conv_layer[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4ywBTy2b6V-"
      },
      "outputs": [],
      "source": [
        "\n",
        "  result = relu.forward(conv_layer[0], conv_layer[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LobN1k3ZdRW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "  result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxA-aY6WCSBD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZvOsNB5AW6G"
      },
      "outputs": [],
      "source": [
        "#@title Class MaxPool Layer\n",
        "class new_maxpool_layer(torch.nn.Module):\n",
        "    def __init__(self, kernel_size: int):\n",
        "        super().__init__()\n",
        "        self.k_size=kernel_size\n",
        "        self.stride = kernel_size\n",
        "        \n",
        "    def forward(self, input):\n",
        "      final_output = []\n",
        "      output_size = math.floor(((input.size(dim=1) - self.k_size)/self.stride) + 1)\n",
        "      for chan in range(input.size(dim=0)):\n",
        "        channel_output = []\n",
        "        row = 0\n",
        "        for r in range(output_size):\n",
        "          slice_mvalues = max_slice(input[chan], self.k_size, self.stride, row)\n",
        "          row += self.stride \n",
        "\n",
        "          channel_output.append(slice_mvalues)\n",
        "        final_output.append(channel_output)\n",
        "      return torch.tensor(final_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0PqWsn_0Kes"
      },
      "outputs": [],
      "source": [
        "\n",
        "  max_input = torch.tensor([[[ 7.,  6.,  0.],\n",
        "                            [ 9.,  7.,  8.],\n",
        "                             [ 4.,  8.,  8.]],\n",
        "\n",
        "                            [[0.,  0., 0.],\n",
        "                             [ 2.,  11., 0.],\n",
        "                              [0.,  3.,  2.]]], dtype=torch.long)\n",
        "  cnn_max = new_maxpool_layer(3)\n",
        "  output = cnn_max.forward(max_input)\n",
        "\n",
        "  print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuRb5beB50zY"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T803DPikWMFr"
      },
      "outputs": [],
      "source": [
        "\n",
        "  example_input = torch.tensor([[0.8757, 0.8018],\n",
        "        [0.5597, 0.4330],\n",
        "        [0.1329, 0.4700],\n",
        "        [0.2481, 0.4330],\n",
        "        [0.3633, 0.2557],\n",
        "        [0.6708, 0.1123],\n",
        "        [0.8782, 0.7748],\n",
        "        [0.4641, 0.4129],\n",
        "        [0.3623, 0.1652],\n",
        "        [0.2499, 0.4253],\n",
        "        [0.6921, 0.5357],\n",
        "        [0.6326, 0.8908],\n",
        "        [0.9433, 0.5875],\n",
        "        [0.2363, 0.8307],\n",
        "        [0.6946, 0.5997],\n",
        "        [0.0659, 0.9280]])\n",
        "  print(\"Start\")\n",
        "  print(example_input)\n",
        "  max_pool = maxpool_layer(2)\n",
        "  result = max_pool.forward(example_input)\n",
        "\n",
        "  test_tensor = torch.tensor([[0.8757],\n",
        "        [0.4700],\n",
        "        [0.6708],\n",
        "        [0.8782],\n",
        "        [0.4253],\n",
        "        [0.8908],\n",
        "        [0.9433],\n",
        "        [0.9280]])\n",
        "  print(\"Ende \")\n",
        "  print(result)\n",
        "  print(torch.eq(result, test_tensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYIGzeuvesBh"
      },
      "outputs": [],
      "source": [
        "\n",
        "  max_pool = maxpool_layer(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck3qCEHfesD3"
      },
      "outputs": [],
      "source": [
        "\n",
        "  result = max_pool.forward(result[0], result[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOXBxZxgekub"
      },
      "outputs": [],
      "source": [
        "\n",
        "  result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za5_mgfffWuj"
      },
      "outputs": [],
      "source": [
        "\n",
        "  array = torch.flatten(result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7r9Q7Rv787z"
      },
      "outputs": [],
      "source": [
        " \n",
        "  array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM8JqNYx7HDs"
      },
      "outputs": [],
      "source": [
        "#@title Class Linear layer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class lin_layer(torch.nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.empty((out_features, in_features)))\n",
        "        self.bias = Parameter(torch.empty(out_features))\n",
        "    def forward(self, input):\n",
        "      \n",
        "      output = torch.matmul(self.weight, input) \n",
        "      output += self.bias\n",
        "      return output\n",
        "      \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMwzJljKYGr8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgwKCnfc1Xb0"
      },
      "outputs": [],
      "source": [
        "\n",
        "  linear = lin_layer(32 * 7 * 7, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGp_gvPt-Dk8"
      },
      "outputs": [],
      "source": [
        "\n",
        "  array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwrkJLlK2i8S"
      },
      "outputs": [],
      "source": [
        "\n",
        "  probs = linear.forward(array, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpPXyUHx-yg7"
      },
      "outputs": [],
      "source": [
        "\n",
        "  probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfkzhcE48_sd"
      },
      "outputs": [],
      "source": [
        "\n",
        "tensor1 = torch.randn(2, 3)\n",
        "tensor2 = torch.randn(3)\n",
        "torch.matmul(tensor1, tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMdI2Mit9CWy"
      },
      "outputs": [],
      "source": [
        "tensor1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC92NC2A9hcz"
      },
      "outputs": [],
      "source": [
        "tensor2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLEhejgP9hgU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIHNbeYd370o"
      },
      "outputs": [],
      "source": [
        "a = torch.randn(2, 3)\n",
        "print(a)\n",
        "print(\"full stop\")\n",
        "b = torch.randn(3)\n",
        "print(b)\n",
        "torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMdo3ozZ6hQX"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([[1,2,3],[6,7,8]])\n",
        "print(a)\n",
        "print(\"full stop\")\n",
        "b = torch.tensor([1, 2, 3])\n",
        "print(b)\n",
        "torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvNLVMCO6qtG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulZaV3Az6qq0"
      },
      "outputs": [],
      "source": [
        "#@title Class CNN\n",
        "#The module torch.nn contains different classess that help you build neural network models. \n",
        "#All models in PyTorch inherit from the subclass nn.Module,\n",
        "\n",
        "import torch.nn as nn\n",
        "#nn makes neural network and adds blocks and layers when given e.g. Conv2d\n",
        "class own_CNN(torch.nn.Module):\n",
        "  #The __init__ method is where we typically define the attributes of a class. \n",
        "  #In our case, all the \"sub-components\" of our model should be defined here, along with any other setting that we wish to save \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = new_conv_layer(in_channels=1,           \n",
        "                out_channels=16,        \n",
        "                kernel_size=5,          \n",
        "                stride=1,                 \n",
        "                padding=2,)\n",
        "        self.relu1 =  new_relu_layer() \n",
        "        self.maxpool1 = new_maxpool_layer(kernel_size=2)  \n",
        "        \n",
        "        self.conv2 = new_conv_layer(16, 32, 5, 1, 2)\n",
        "        self.relu2 = new_relu_layer()\n",
        "        self.maxpool2 = new_maxpool_layer(kernel_size=2)           \n",
        "        \n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = lin_layer(32 * 7 * 7, 10)  # in_features – size of each input sample\n",
        "                                              # out_features – size of each output sample\n",
        "                                              # bias – If set to False, the layer will not learn an additive bias. Default: True\n",
        "\n",
        "    \n",
        "    def forward(self, x): #x = tensor image\n",
        "        x = self.conv1(x)\n",
        "        #print(\"forward after conv1\", x.size())\n",
        "        #print(\"x after conv1\", x)\n",
        "        x = self.relu1(x)\n",
        "        #print(\"forward after relu1\", x.size())\n",
        "        #print(\"x after relu1\", x)\n",
        "        x = self.maxpool1(x)\n",
        "        #print(\"x after maxpool1\", x)\n",
        "       # print(\"forward after maxpool1\", x.size())\n",
        "        \n",
        "\n",
        "        x = self.conv2(x)\n",
        "        #print(\"forward after conv2\", x.size())\n",
        "        x = self.relu2(x)\n",
        "        #print(\"forward after relu2\", x.size())\n",
        "        x = self.maxpool2(x)\n",
        "        #print(\"forward after maxpool2\", x.size())\n",
        "\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7) 32*7*7 = input feature of fully connected layer\n",
        "        #@Q: What does flatten mean?\n",
        "        x = torch.flatten(x)\n",
        "        output = self.out(x)\n",
        "        return output, x    # return x for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7y891ST6qoX"
      },
      "outputs": [],
      "source": [
        "own_cnn = own_CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OyksVWR-5OY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFGlUDLNfW5q"
      },
      "outputs": [],
      "source": [
        "print(own_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_wjrsdCNxL"
      },
      "source": [
        "# PyTorch Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPRE-IRnncK2"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(loaders['train']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxjNBVsyni-p"
      },
      "outputs": [],
      "source": [
        "images.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp-g_vnTncTN"
      },
      "outputs": [],
      "source": [
        "images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiKle8sP4ntU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmVluoO0Eo1u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1SU40eo6a5J"
      },
      "outputs": [],
      "source": [
        "#@title Import CrossEntropyLoss\n",
        "loss_func = nn.CrossEntropyLoss()   \n",
        "loss_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3axx_Ido6a3A"
      },
      "outputs": [],
      "source": [
        "#@title Import Adam\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(own_cnn.parameters(), lr = 0.01)   \n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqWFh3AA6a04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F657XResT3v3"
      },
      "outputs": [],
      "source": [
        "#@title CNN TRAIN\n",
        "#train the model\n",
        "from torch.autograd import Variable\n",
        "num_epochs = 1\n",
        "\n",
        "\n",
        "#@TODO: name that goddamn function differently, it has no business being called the same as train() when they're different\n",
        "def train(num_epochs, own_cnn, loaders):\n",
        "    \n",
        "    # set the model in training mode\n",
        "    own_cnn.train()\n",
        "        \n",
        "    # Train the model\n",
        "    total_step = len(loaders['train']) #600 for 600 batches a 100 \n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(loaders['train']):            \n",
        "            # gives batch data, normalize x when iterate train_loader\n",
        "            b_x = Variable(images)   # batch x\n",
        "            b_y = Variable(labels)   # batch y\n",
        "            \n",
        "            for j in range(len(labels)):\n",
        "              imgo = b_x[j]\n",
        "              output = own_cnn(b_x[j])[0]               \n",
        "              loss = loss_func(output, b_y[j])\n",
        "            \n",
        "              # clear gradients for this training step   \n",
        "              optimizer.zero_grad()           \n",
        "            \n",
        "              # backpropagation, compute gradients \n",
        "              loss.backward()    \n",
        "              # apply gradients             \n",
        "              optimizer.step()                \n",
        "            \n",
        "              if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "train(num_epochs, own_cnn, loaders)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfhX7DYX2EBO"
      },
      "outputs": [],
      "source": [
        "number = 0\n",
        "images, labels = next(iter(loaders['train']))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ofGTz6N2tyH"
      },
      "outputs": [],
      "source": [
        "images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My_xjonW2EEL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDrFKx93T3yb"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test data\n",
        "def test():\n",
        "    # Test the model\n",
        "    #model.eval() to set dropout and batch normalization layers to evaluation \n",
        "    #mode before running inference.\n",
        "    cnn.eval()\n",
        "\n",
        "    #test\n",
        "    idx = 0\n",
        "\n",
        "    # with statement in Python is used in exception handling to make the code cleaner \n",
        "    # and much more readable. (Same as try, but shorter, hence cleaner)\n",
        "\n",
        "    #Context-manager that disabled gradient calculation. Disabling gradient calculation \n",
        "    #is useful for inference, when you are sure that you will not call Tensor.backward(). \n",
        "    #It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in loaders['test']:\n",
        "          #do cnn with test images & labels\n",
        "            test_output, last_layer = cnn(images)\n",
        "\n",
        "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
        " \n",
        "              \n",
        "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
        "    \n",
        "test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLJnDt1vEcD-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPhqdt-YT30w"
      },
      "outputs": [],
      "source": [
        "#Print 10 predictions from test data\n",
        "sample = next(iter(loaders['test']))\n",
        "imgs, lbls = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZIL7G7W5kOq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwGeTMjuT31n"
      },
      "outputs": [],
      "source": [
        "actual_number = lbls[:10].numpy()\n",
        "actual_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynDt9q3YT34X"
      },
      "outputs": [],
      "source": [
        "test_output, last_layer = cnn(imgs[:10])\n",
        "pred_y = torch.max(test_output, 1)[1].tolist()\n",
        "print(f'Prediction number: {pred_y}')\n",
        "print(f'Actual number: {actual_number}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eI2T_TgT38b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2auuutprT397"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDBEhH0KLDXqco7YL494Sp"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}